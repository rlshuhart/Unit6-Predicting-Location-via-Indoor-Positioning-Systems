---
title: "Modern R Notebook"
output: html_notebook
---



```{r, include=FALSE}
# Libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(DataExplorer)
library(class) #KNN Classifier
library(FNN) #KNN Regression
```

## Import Pre-processed Data
```{r}
# Processed Data
offline <- readRDS("../data/processed/offline.rds")
online_allmacs <- readRDS("../data/processed/online_allmacs.rds")


# Signal Lists

# All accesspoints
allsigs <- c(
  "sig_cd", # Access Point #?
  "sig_c0", # Access Point #?
  "sig_c6", # Access Point #?
  "sig_81", # Access Point #?
  "sig_8a", # Access Point #?
  "sig_8d", # Access Point #?
  "sig_90"  # Access Point #?
             )

# drop e1:c0 <- should move this to where it become relevant
keep_ddcd_sigs <- c(
  "sig_cd", # Access Point #?
  "sig_c6", # Access Point #?
  "sig_81", # Access Point #?
  "sig_8a", # Access Point #?
  "sig_8d", # Access Point #?
  "sig_90"  # Access Point #?
             )

# drop dd:cd <- should move this to where it become relevant
keep_e1c0_sigs <- c( 
  "sig_c0", # Access Point #?
  "sig_c6", # Access Point #?
  "sig_81", # Access Point #?
  "sig_8a", # Access Point #?
  "sig_8d", # Access Point #?
  "sig_90"  # Access Point #?
             )
```
### Data Description
Offline data is this ... and is use as training...

Online data is the test data...

## Create Data Set by Time
```{r}
offlineByTime <- group_by(offline, time, posXY, mac,  angle) %>%
  summarize(avgSig = mean(signal)) %>%
  spread(mac, avgSig) %>%
  ungroup()%>%
  rename(sig_cd = `00:0f:a3:39:dd:cd`,
         sig_c0 = `00:0f:a3:39:e1:c0`, 
         sig_c6 = `00:14:bf:3b:c7:c6`,
         sig_81 = `00:14:bf:b1:97:81`,
         sig_8a = `00:14:bf:b1:97:8a`,
         sig_8d = `00:14:bf:b1:97:8d`,
         sig_90 = `00:14:bf:b1:97:90`)

head(offlineByTime)
```
```{r}
dim(offlineByTime)
```
The offlineByTime data frame is generated by pivoting the mac addresses and signal strength from rows to columns. This pivot makes the shape of the data wider, but reduces the rows from 914,951 to 146,074. The columns 'orientation', 'rawTime', 'posX', and 'posY' are excluded for this view of the data. 

## Exploratoration of Offline Data
### Missing Data
```{r}
offlineByTime[,allsigs] %>% summarize_each(funs(sum(is.na(.))))
```
```{r}
PlotMissing(offlineByTime)
```

[...Insert commentary about the missing data...]

```{r}
paste("There are ", format(sum(complete.cases(offlineByTime)),big.mark=",",scientific=FALSE),
      " (", sprintf("%.1f", sum(complete.cases(offlineByTime))/nrow(offlineByTime)*100), "%)", 
      " complete rows of data.", sep="")
```

```{r}
AP <- data.frame(Label=c("sig_c0", "sig_8a", "sig_c6", "sig_90", "sig_8d", "sig_81"),
                 posX=c(7.5,2.5,12.8,1,33.5,33.5), 
                 posY=c(6.3,-.8,-2.8,14.0,9.3,2.8), 
                 Type="Access Point")

offlinePoints <- unique(offline[,c("posX","posY")])
offlinePoints$Type <- "Offine - Training"

onlinePoints <- unique(online_allmacs[,c("posX","posY")])
onlinePoints$Type <- "Online - Test"

building <- rbind(offlinePoints, select(AP, -Label), onlinePoints)

ggplot(building, aes(x=posX, y=posY)) + 
  geom_point(aes(shape=Type, color=Type)) + 
  geom_text(data=filter(AP, !(Label %in% c("sig_90", "sig_8d"))), aes(label=Label), nudge_y = -.6) +
  geom_text(data=filter(AP, Label == "sig_90"), aes(label=Label), nudge_x = 2) +
  geom_text(data=filter(AP, Label == "sig_8d"), aes(label=Label), nudge_x = -2) +
  labs(title="Floor Plan Training Points") + 
  scale_shape_manual(values = c(8,16,1)) +
  scale_colour_manual(values=c("red","black","blue")) +
  theme_bw() +
  theme(axis.title.x=element_blank(), 
        axis.title.y=element_blank(), 
        axis.text.x=element_blank(), 
        axis.text.y=element_blank(),
        panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(),
        axis.ticks=element_blank())
```


### Histogram of Signal Strengths
```{r}
HistogramContinuous(offlineByTime[,allsigs])
```

### Correlation of Signal Stregths <- Might be something to dicuss here or maybe not
```{r}
CorrelationContinuous(offlineByTime[,allsigs], use = "na.or.complete")
```

## Create Train Data Set by Average Signal
```{r}
trainByAvgSig <- group_by(offline, posXY, posX, posY, mac,  angle) %>%
  summarize(avgSig = mean(signal)) %>%
  spread(mac, avgSig) %>%
  ungroup()%>%
  rename(sig_cd = `00:0f:a3:39:dd:cd`,
         sig_c0 = `00:0f:a3:39:e1:c0`, 
         sig_c6 = `00:14:bf:3b:c7:c6`,
         sig_81 = `00:14:bf:b1:97:81`,
         sig_8a = `00:14:bf:b1:97:8a`,
         sig_8d = `00:14:bf:b1:97:8d`,
         sig_90 = `00:14:bf:b1:97:90`)

head(trainByAvgSig)

```
### Check if Missing Data on from Average Aggregation
```{r}
trainByAvgSig[,allsigs] %>% summarize_each(funs(sum(is.na(.))))
```

```{r}
testAllMacs <- group_by(online_allmacs, posXY, posX, posY, mac,  angle) %>%
  summarize(avgSig = mean(signal)) %>%
  spread(mac, avgSig)%>%
  ungroup()%>%
  rename(sig_cd = `00:0f:a3:39:dd:cd`,
         sig_c0 = `00:0f:a3:39:e1:c0`, 
         sig_c6 = `00:14:bf:3b:c7:c6`,
         sig_81 = `00:14:bf:b1:97:81`,
         sig_8a = `00:14:bf:b1:97:8a`,
         sig_8d = `00:14:bf:b1:97:8d`,
         sig_90 = `00:14:bf:b1:97:90`) 

head(testAllMacs)
```

### Using KNN Regression for K = 1, 3, & 5
```{r}
trainPosX_Y <- trainByAvgSig$posX
trainPosX_X <- select(trainByAvgSig, -posXY, -posX, -posY)
testPosX_X <- select(testAllMacs, -posXY, -posX, -posY)

trainPosY_Y <- trainByAvgSig$posY
trainPosY_X <- select(trainByAvgSig, -posXY, -posX, -posY)
testPosY_X <- select(testAllMacs, -posXY, -posX, -posY)

#k = 1
test_estXk1 <- knn.reg(trainPosX_X, testPosX_X, trainPosX_Y, k=1)$pred
test_estYk1 <- knn.reg(trainPosY_X, testPosY_X, trainPosY_Y, k=1)$pred
test_estXYk1 <- data.frame(posX = test_estXk1, posY = test_estYk1)

#k = 3
test_estXk3 <- knn.reg(trainPosX_X, testPosX_X, trainPosX_Y, k=3)$pred
test_estYk3 <- knn.reg(trainPosY_X, testPosY_X, trainPosY_Y, k=3)$pred
test_estXYk3 <- data.frame(posX = test_estXk3, posY = test_estYk3)

#k = 5
test_estXk5 <- knn.reg(trainPosX_X, testPosX_X, trainPosX_Y, k=5)$pred
test_estYk5 <- knn.reg(trainPosY_X, testPosY_X, trainPosY_Y, k=5)$pred
test_estXYk5 <- data.frame(posX = test_estXk5, posY = test_estYk5)

#MSE
#sum( rowSums( (estXY - actualXY)^2) )
sum( rowSums( (test_estXYk1 - testAllMacs[,c("posX", "posY")])^2) )
sum( rowSums( (test_estXYk3 - testAllMacs[,c("posX", "posY")])^2) )
sum( rowSums( (test_estXYk5 - testAllMacs[,c("posX", "posY")])^2) )
```

### Plot MSE for k 1-20 using All AP signals
```{r}
k_compare_func <- function(trainPosX_X, 
                           trainPosY_X, 
                           testPosX_X, 
                           testPosY_X,
                           validatation,
                           i){
  estX <- knn.reg(trainPosX_X, testPosX_X, trainPosX_Y, k=i)$pred
  estY <- knn.reg(trainPosY_X, testPosY_X, trainPosY_Y, k=i)$pred
  
  estXYk <- data.frame(posX = estX, posY = estY)
  
  sum( rowSums( (estXYk - validatation)^2) )
  
}

validatation <- testAllMacs[,c("posX", "posY")]
k=numeric()
MSE=numeric()
for (i in 1:range(20)){
  k[i] <- i
  MSE[i] <- k_compare_func(trainPosX_X, trainPosY_X, testPosX_X, 
                                  testPosY_X, validatation, i)
}

k_compare <- data.frame(k, MSE)
print(paste("The best MSE:",top_n(k_compare,-1,MSE)[2], "with a k of:", top_n(k_compare,-1,MSE)[1])) # Negative 1 is to get lowest MSE
```

```{r}

ggplot(k_compare, aes(k, MSE)) + geom_line() + theme_classic()

```

### Without e1:c0
```{r}
validatation <- testAllMacs[,c("posX", "posY")]
k=numeric()
MSE=numeric()
for (i in 1:range(20)){
  k[i] <- i
  MSE[i] <- k_compare_func(trainPosX_X[,c("angle",keep_ddcd_sigs)], 
                           trainPosY_X[,c("angle",keep_ddcd_sigs)], 
                           testPosX_X[,c("angle",keep_ddcd_sigs)],
                           testPosY_X[,c("angle",keep_ddcd_sigs)], validatation, i)
}

k_compare_keep_ddcd <- data.frame(k, MSE)
print(paste("The best MSE:",top_n(k_compare_keep_ddcd,-1,MSE)[2], "with a k of:", top_n(k_compare_keep_ddcd,-1,MSE)[1]))# Negative 1 is to get lowest MSE
```

```{r}
ggplot(k_compare_keep_ddcd, aes(k, MSE)) + geom_line() + theme_classic()
```

### Without dd:cd
```{r}
validatation <- testAllMacs[,c("posX", "posY")]
k=numeric()
MSE=numeric()
for (i in 1:range(20)){
  k[i] <- i
  MSE[i] <- k_compare_func(trainPosX_X[,c("angle",keep_e1c0_sigs)], 
                           trainPosY_X[,c("angle",keep_e1c0_sigs)], 
                           testPosX_X[,c("angle",keep_e1c0_sigs)],
                           testPosY_X[,c("angle",keep_e1c0_sigs)], validatation, i)
}
k_compare_keep_e1c0 <- data.frame(k, MSE)
print(paste("The best MSE:",top_n(k_compare_keep_e1c0,-1,MSE)[2], "with a k of:", top_n(k_compare_keep_e1c0,-1,MSE)[1])) # Negative 1 is to get lowest MSE
```

```{r}
ggplot(k_compare_keep_e1c0, aes(k, MSE)) + geom_line() + theme_classic()
```

training set by time - done


Training set averaged signal - done


Training set weighted average signal

keep only 00:0f:a3:39:e1:c0 - done for no weighting

keep only 00:0f:a3:39:dd:cd - done for no weighting

inlcude both - done for no weighting

*Adding angle seems to make it worse. currently not just looking at the closest angles.

## Which of these two MAC addresses should be used and which should not be used for RTLS? 
It appears leaving out e1:co has the lowest MSE 


## Which MAC address yields the best prediction of location?
00:0f:a3:39:dd:cd


## Does using data for both MAC addresses simultaneously yield more, or less, accurate prediction of location?
Less accurate


For what range of values of weights are you able to obtain better prediction values than for the unweighted k-nearest neighbor approach? 

## Weighted
$\frac{1/d}{\sum_{i=1}^k 1/d_i}$ 
```{r}
# W
(1/trainPosX_X[,keep_e1c0_sigs]) / rowSums(1/trainPosX_X[,keep_e1c0_sigs])

```

```{r}
trainPosX_X[,keep_e1c0_sigs]
```

