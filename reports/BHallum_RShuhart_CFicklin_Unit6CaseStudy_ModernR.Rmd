---
title: "Predicting Location via Indoor Positioning Systems"
author: "Brett Hallum, Chris Ficklin, and Ryan Shuhart"
date: "February 2017"
output:
  html_notebook: default
  html_document: default
  pdf_document: default
subtitle: MSDS 7333-401
---

## Abstract

Indoor positioning systems (IPS) calculate the location of people and equipment in locations like offices and warehouses which are not served by other positioning technologies such as GPS. By analyzing relative wireless signal strength received from various fixed Wi-Fi devices on the premises (e.g. access points throughout a building), location can be calculated in near real-time with high precision. In this case study we develop an IPS based on pre-collected data from a floor of a university building. Initially we employ a k-nearest-neighbor (KNN) algorithm and refine it to minimize its measure error. Next we attempt to improve on these results by applying a weighting function to the recorded signals in an effort to give greater influence to closer signal sources. Finally, we compare our results and present areas of future study to improve on our design.


## Introduction

The low cost and near ubiquity of wireless networking infrastructure in buildings has brought with it a long desired side benefit, the ability to track people and equipment moving through a space in near real-time. The goal of knowing who and what are in a location and the ability to track their movements has many applications for which solutions have long been sought. In grocery stores, for instance, significant resources were commonly used to study the paths shoppers took from the time they arrived until they left. Data could be used to plan the layout of goods, to sell shelf space at a premium, and to assist in dedicating loss prevention resources. These efforts were costly and nowhere near real-time, and did not easily account for future layout changes.

Now with Wi-Fi equipment such as access points in place or easily deployed, it is possible to track the location of devices that continuously communicate with the fixed wireless infrastructure. Equipment such as laptops can be tracked for security purposes within an office, for instance, to ensure that they stay on site or to record when and where they departed. Such information can flag alerts or be cross-referenced with other access controls such as key cards and video surveillance to ensure the security of physical and intellectual property.

People who carry phones or other equipment meant to communicate with the Wi-Fi access points can be similarly tracked. Of important note is the fact that a device need not fully connect to a wireless network. It is sufficient that the radio merely be turned on since it regularly identifies itself to seek out potential access points with which it may connect.

In this case study we use the R language to process raw data collected from an existing wireless infrastructure and develop an analytical engine to create an indoor positioning system (IPS) to achieve this location awareness.


## Description of Data

Setting up IPS requires an initial data collection phase wherein a survey of the installed wireless infrastructure is completed to determine where access points are located and identify their unique signatures called media access control (MAC) addresses. Next, a systematic map of received signal strength is created by moving a wireless device through the entirely of the location, with regular spacing and orientation, and recording the signal strengths of all access points it detects. Multiple measurements at each location and orientation are collected since signals can vary somewhat due to anomalies caused by other device activity and wireless interference. Once complete, this dataset represents a thorough collection of expected signal strengths at any location throughout the premises.

Determining the location of a future wireless device in the area requires comparing its relative signal strength at multiple access points to the originally mapped data. This process is not unlike the techniques used to predict device locations via global positioning satellites. The difference here is that Wi-Fi devices are ubiquitous and work well indoors, and give access to signal strength data at the controlled infrastructure rather than at the individual device exclusively (i.e. only the GPS enabled device knows where it is, the satellites do not). To achieve this, a test dataset is collected using a similar wireless device at various known locations on the premises. With this information we formulate an optimal positioning algorithm by testing and cross-validating its predictive performance against the known locations in the test set.

Data for this case study comes from a floor in a building on the campus of the University of Mannheim hosted by the CRAWDAD project (Community Resource for Archiving Wireless Data at Dartmouth). The floor measures approximately 15 meters by 36 meters. There are six access points providing wireless connectivity to the floor. The training dataset (hereafter referred to as “offline data”) was collected in the hallways of this floor along a grid with 1-meter spacing resulting in 166 locations. Signals were recorded at each measurement point with a handheld device at 8 orientations, each 45 degrees apart (0, 45, 90, 135, 180…). At each location and orientation, 110 measurements were attempted, however not all access point were reachable for every connection attempt due to distance factors or other anomalies.

Extraneous signal data from other wireless devices present but not part of the controlled measurement set is also collected in the raw data. These are likely from temporary Wi-Fi hotspots, access points in other parts of the building, and devices set up in ad-hoc (peer-to-peer) mode. We create preprocessing steps to detect and clean these unwanted observations.

Interestingly, though the documentation only lists six wireless access points on this floor, we discover seven apparently legitimate MAC addresses. We hypothesize that one access point contains dual radios and thus two MAC addresses. Though it is not initially clear how we will handle the additional data, signal observations from all seven MAC addresses are retained for analysis. As such, the offline data contains a theoretical maximum of 1,022,560 unique observations of interest to our study (110 readings from seven access points at 166 locations each with 8 orientations). The test dataset, or “online data”, is comprised of 60 randomly selected locations throughout the floor, but is otherwise similar to the offline data and prepared for analysis in the same way.

In the following section we more closely examine the structure of the raw data, describe the steps taken to clean the extraneous information, and determine the most efficient way to parse and manipulate it for our analysis.


##Raw Data Preprocessing

Each observation in the raw data collected from the hand-held measuring device is recorded on a single line with values separated by semicolons. The first data line in the offline set is given as an example below, broken up for better legibility. The online dataset follows the same format.

t=1139643118358;id=00:02:2D:21:0F:33;pos=0.0,0.0,0.0;degree=0.0;<br>
00:14:bf:b1:97:8a=-38,2437000000,3;<br>
00:14:bf:b1:97:90=-56,2427000000,3;<br>
00:0f:a3:39:e1:c0=-53,2462000000,3;<br>
00:14:bf:b1:97:8d=-65,2442000000,3;<br>
00:14:bf:b1:97:81=-65,2422000000,3;<br>
00:14:bf:3b:c7:c6=-66,2432000000,3;<br>
00:0f:a3:39:dd:cd=-75,2412000000,3;<br>
00:0f:a3:39:e0:4b=-78,2462000000,3;<br>
00:0f:a3:39:e2:10=-87,2437000000,3;<br>
02:64:fb:68:52:e6=-88,2447000000,1;<br>
02:00:42:55:31:00=-84,2457000000,1

The first value is the timestamp of the observation in milliseconds since midnight, January 1, 1970 UTC. Since R’s Date-Time class takes this parameter in seconds, it is properly scaled before being used to calculate a traditional date and time. The more precise time in milliseconds is also retained for potential use later.

The id variable represents the MAC address of the handheld scanning device. Since this is always the same, it serves no purpose and is discarded.

The pos variable contains three coordinates (x, y, z) representing the position of the device when the reading was taken. All measurements were collected on a single floor, so after verifying that the z coordinate remains 0.0 throughout the data, it is removed leaving just an (x, y) plane of observations.

The degree value represents the orientation of the scanning device. Recall that each position is scanned at 8 orientations, 45 degrees apart. Understandably it is difficult to hold the device in the perfect direction each time. As such, the values for this field tend to hover around the expected orientation when not perfectly achieving it. In this example the degree of 0.0 is spot on, but many others are not. We retain the recorded orientation reading, but also normalize these values in a field called “angle” which represents their intended degree. In the case of the 0-degree orientation, for instance, a reading 2.4 degrees or 358.2 degrees would both be stored as the integer 0 in the angle field.

The remaining items are the MAC addresses and associated information of every access point or ad-hoc device detected during that reading. This value has four parts: The address, the signal strength, the channel frequency, and an indicator value representing the device mode (access point = 3, ad-hoc mode = 1). We know immediately that we have no interest in any ad-hoc devices, so those will be removed. Since we are not told which MAC addresses belong to the access points of interest, the remaining addresses need some analysis before determining which belong to the fixed access points on this floor that we wish to use in the creation of out IPS. There are several reasons why stray MAC addresses would be recorded. They could be picked up from elsewhere in the building or belong to temporary Wi-Fi hotspots, for example. In either case we expect them to show up less frequently than those belonging to the fixed access points on the floor.

Upon exploration, we find a total of 12 unique access point addresses appearing at least once within the data. By viewing their frequency of occurrence, we see that all but seven occur with significantly less regularity. As mentioned earlier, we expected only six MAC addresses corresponding to the six access points indicated on the floor plan, so it is not immediately clear why there are seven or which, if any, should still be removed. For now, those obviously believed to be extraneous are discarded and the seven most frequent are retained until further analysis.

Next is the signal strength detected for every MAC address. This value is a negative number in Decibel-milliwatts with higher values (those closest to zero) representing greater signal strength. These are essential for our analysis.

The last value is the channel frequency. Data exploration reveals that this number never changes for a given access point. Since it adds no meaningful information, it is also excluded.

With the initial exploration and cleaning complete, attention is focused on how to most efficiently format the data for future analysis. One option is to create a data frame with a similar shape to the raw data, i.e. one record for each location/orientation/reading (out of 110). In this case all MAC address and their associated signal strengths would have a place in each record. Though it would result in fewer rows, this is less optimal for several reasons. First, not every MAC address is detected in every attempt, which would leave many null values. And second, this format provides less flexibility to continue manipulating and discreetly analyzing the data throughout the remaining work. Instead we choose to reform the data such that each record represents the data from a single detection of each MAC address with the fields shown below.

time&emsp;YYYY-MM-DD HH-MM-SS<br>
posX&emsp;Integer from 0-33<br>
posY&emsp;Integer from 0-13<br>
orientation&emsp;Recorded orientation (float)<br>
MAC&emsp;Individual MAC address<br>
signal&emsp;Recorded signal strength<br>
rawTime&emsp;Retained time in milliseconds<br>
angle&emsp;Normalized orientation in 45 degree intervals<br>
posXY&emsp;A concatenation of posX and posY in X-Y format<br>

In this way, there are up to seven records for every location, orientation, and time, with each only having a single MAC address and signal. Again, this same format is used for both the offline training data and online test data.

With the preprocessing complete, we store each dataframe as an RDS object for faster access and smaller file size and continue to explore the data and develop our IPS.



```{r, include=FALSE}
# Libraries
library(dplyr) # Data transformations
library(tidyr) # Data transformations
library(ggplot2) # Visualizations
library(data.table)
library(scales)
library(gridExtra)
library(stats)
library(knitr) # Markdown tables
library(DataExplorer) # Simplyfied common ggplots
library(FNN) #KNN Regression
```


```{r}
# Import Pre-processed Data
offline <- readRDS("../data/processed/offline.rds")
online_allmacs <- readRDS("../data/processed/online_allmacs.rds")

```
### Data Description



```{r}
#### Create Data Set by Time
offlineByTime <- group_by(offline, time, posXY, mac,  angle) %>%
  summarize(avgSig = mean(signal)) %>%
  spread(mac, avgSig) %>%
  ungroup()%>%
  rename(sig_cd = `00:0f:a3:39:dd:cd`,
         sig_c0 = `00:0f:a3:39:e1:c0`, 
         sig_c6 = `00:14:bf:3b:c7:c6`,
         sig_81 = `00:14:bf:b1:97:81`,
         sig_8a = `00:14:bf:b1:97:8a`,
         sig_8d = `00:14:bf:b1:97:8d`,
         sig_90 = `00:14:bf:b1:97:90`)

#During the pdf process, knitr will lable the table number. Looks worse in html
kable(offlineByTime[1:5,], caption = "Offline Data - First Observations")
```
```{r, echo=FALSE}
# dim(offlineByTime)
```
The offlineByTime data frame is generated by pivoting the mac addresses and signal strength from rows to columns. This pivot makes the shape of the data wider, but reduces the rows from 914,951 to 146,074. The columns 'orientation', 'rawTime', 'posX', and 'posY' are excluded for this view of the data. 

### Exploration of Offline Data

```{r}
AP <- data.frame(Label=c("sig_c0", "sig_8a", "sig_c6", "sig_90", "sig_8d", "sig_81"),
                 posX=c(7.5,2.5,12.8,1,33.5,33.5), 
                 posY=c(6.3,-.8,-2.8,14.0,9.3,2.8), 
                 Type="Access Point")

offlinePoints <- unique(offline[,c("posX","posY")])
offlinePoints$Type <- "Offine - Training"

onlinePoints <- unique(online_allmacs[,c("posX","posY")])
onlinePoints$Type <- "Online - Test"

building <- rbind(offlinePoints, select(AP, -Label), onlinePoints)

ggplot(building, aes(x=posX, y=posY)) + 
  geom_point(aes(shape=Type, color=Type)) + 
  geom_text(data=filter(AP, !(Label %in% c("sig_90", "sig_8d"))), aes(label=Label), nudge_y = -.6) +
  geom_text(data=filter(AP, Label == "sig_90"), aes(label=Label), nudge_x = 2) +
  geom_text(data=filter(AP, Label == "sig_8d"), aes(label=Label), nudge_x = -2) +
  labs(title="(Fig. 1) Floor Plan") + 
  scale_shape_manual(values = c(8,16,16)) +
  scale_colour_manual(values=c("red","black","#0DC3FF")) +
  theme_bw() +
  theme(axis.title.x=element_blank(), 
        axis.title.y=element_blank(), 
        axis.text.x=element_blank(), 
        axis.text.y=element_blank(),
        panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(),
        axis.ticks=element_blank())
```
Figure 1 plots the current floor plan and the locations of the training points, seen in black, and the test points, seen in blue. The training points, or Offline data, are 1 meter apart.

### Offline Missing Data
```{r}
# Modified from DataExplorer library by boxuancui 
# https://github.com/boxuancui/DataExplorer
plotMissing <- function(data, title=NULL) {
  ## Declare variable first to pass R CMD check
  feature <- num_missing <- pct_missing <- group <- NULL
  ## Check if input is data.table
  is_data_table <- TRUE
  ## Detect input data class
  data_class <- class(data)
  ## Set data to data.table
  if (!is_data_table) {data <- data.table(data)}
  ## Extract missing value distribution
  missing_value <- data.table("feature" = names(data), "num_missing" = sapply(data, function(x) {sum(is.na(x))}))
  missing_value[, feature := factor(feature, levels = feature[order(-rank(num_missing))])]
  missing_value[, pct_missing := num_missing / nrow(data)]
  missing_value[pct_missing < 0.05, group := "Good"]
  missing_value[pct_missing >= 0.05 & pct_missing < 0.4, group := "OK"]
  missing_value[pct_missing >= 0.4 & pct_missing < 0.8, group := "Bad"]
  missing_value[pct_missing >= 0.8, group := "Remove"][]
  ## Set data class back to original
  if (!is_data_table) {class(missing_value) <- data_class}
  ## Create ggplot object
  output <- ggplot(missing_value, aes_string(x = "feature", y = "num_missing", fill = "group")) +
    geom_bar(stat = "identity", colour = "black", alpha = 0.4) +
    geom_text(aes(label = paste0(round(100 * pct_missing, 0), "%")), hjust = -0.15, size = 3.5) +
    scale_fill_manual("Group", values = c("Good" = "#1a9641", "OK" = "#a6d96a", "Bad" = "#fdae61", "Remove" = "#d7191c"), breaks = c("Good", "OK", "Bad", "Remove")) +
    scale_y_continuous(labels = comma) +
    theme(legend.position = c("bottom")) + coord_flip() +
    xlab("Features") + ylab("Number of missing rows") + ggtitle(title)
  ## Print plot
  print(output)
  ## Set return object
  return(invisible(missing_value))
}

plotMissing(offlineByTime, "(Fig. 2) - Offline Missing Data")
```


Many of the access points do not receive data about each of the data points from the device. From the missing data, we see that each receiver misses about 18% of the signals produced by emitting device. This contrasts with 2 of the MAC addresses, 00:0f:a3:39:dd:cd and 00:0f:a3:39:e1:c0, which miss around 1% of the signals emitted.

```{r, echo=FALSE}
paste("There are ", format(sum(complete.cases(offlineByTime)),big.mark=",",scientific=FALSE),
      " (", sprintf("%.1f", sum(complete.cases(offlineByTime))/nrow(offlineByTime)*100), "%)", 
      " complete rows of data.", sep="")
```



#### (Fig. 3) Histogram of Signal Strengths
```{r}
# This type of plot does not allow a title of the grid
HistogramContinuous(offlineByTime %>% select(-posXY, -time, -angle))
```
The above histograms show the frequency of signal strengths recorded for each of the access points producing signals. The further to the right on each of the graphs, the stronger the signal is. The signal strength at any given point is related to the distance away from the source.

#### Using Average Signal for Offline Data
```{r}
offlineByAvgSig <- group_by(offline, posXY, posX, posY, mac,  angle) %>%
  summarize(avgSig = mean(signal)) %>%
  spread(mac, avgSig) %>%
  ungroup()%>%
  rename(sig_cd = `00:0f:a3:39:dd:cd`,
         sig_c0 = `00:0f:a3:39:e1:c0`, 
         sig_c6 = `00:14:bf:3b:c7:c6`,
         sig_81 = `00:14:bf:b1:97:81`,
         sig_8a = `00:14:bf:b1:97:8a`,
         sig_8d = `00:14:bf:b1:97:8d`,
         sig_90 = `00:14:bf:b1:97:90`)

kable(select(offlineByAvgSig[1:5,], -posXY), caption="Offline Data - First Observations of Signal Averages by Position and Angle")
```
To account for the multiple entries of data for a given time, angle, position, and MAC address, the signal strengths are averaged to provide a single row of signal values for a given reading. This provides us with an appropriate training data set without repeats of data points.

### Online Data
Online Data has duplicate observations given the time, position, mac, and angle. Similar to the training data set above, the signal strengths will need to be averaged for situations where these tuples of data occur, resulting in a single series of signal data for a given position, mac address and angle.
```{r}
percDuplicated <- nrow(online_allmacs[duplicated(online_allmacs[,c("time", "posXY", "mac", "angle")]),])/nrow(online_allmacs)

paste(sprintf("%.1f", percDuplicated*100), "% of the online observations are duplicated.", sep="")
```

The online data used for KNN is grouped by access point, position, and angle and will average each of the signal observations. This averaging is done, as noted above, to account for multiple positions, angle and MAC addresses having multiple signal readings.
```{r}
onlineByAvgSig <- group_by(online_allmacs, posXY, posX, posY, mac,  angle) %>%
  summarize(avgSig = mean(signal)) %>%
  spread(mac, avgSig)%>%
  ungroup()%>%
  rename(sig_cd = `00:0f:a3:39:dd:cd`,
         sig_c0 = `00:0f:a3:39:e1:c0`, 
         sig_c6 = `00:14:bf:3b:c7:c6`,
         sig_81 = `00:14:bf:b1:97:81`,
         sig_8a = `00:14:bf:b1:97:8a`,
         sig_8d = `00:14:bf:b1:97:8d`,
         sig_90 = `00:14:bf:b1:97:90`) 

kable(select(onlineByAvgSig[1:5,], -posXY), caption="Online Data - First Observations of Signal Averages by Position and Angle")
```


### Benchmark Using KNN Regression Without Consideration to Angle
```{r}
# function to estimate using KNN the X Y of the online data
predictXYKNN <- function(offline_signals, online_signals, 
                         offline_posX, offline_posY, k){
  
  estX <- knn.reg(offline_signals, online_signals, offline_posX$posX, k=k)$pred
  estY <- knn.reg(offline_signals, online_signals, offline_posY$posY, k=k)$pred
  
  estXYk <- data.frame(posXest = estX, posYest = estY)
  
  return(estXYk)
}


offlinePosX <- select(offlineByAvgSig, posX)
offlinePosY <- select(offlineByAvgSig, posY)
offline_signals <- select(offlineByAvgSig, -posXY, -posX, -posY, -angle)
online_signals <- select(onlineByAvgSig, -posXY, -posX, -posY, -angle)
online_signals_val <- select(onlineByAvgSig, posX, posY)

ks=numeric()
MSE=numeric()

for (k in 1:20){
  ks[k] <- k
  results <- predictXYKNN(offline_signals, online_signals, 
                          offlinePosX, offlinePosY, k)
  results <- cbind(results, online_signals_val)
  MSE[k] <- sum( rowSums( (results[,c("posXest","posYest")] - results[,c("posX","posY")])^2) )
}

signals_only <- data.frame(k=ks, MSE=MSE)
signals_only$Method <- "Benchmark"

ggplot(signals_only, aes(k, MSE)) + 
  geom_line(size=.9) + 
  theme_classic()

```
```{r, echo=FALSE}
kable(signals_only[,c("k", "MSE")] %>% 
        top_n(-1,MSE), 
      caption="Benchmark - All Signals Without Consideration to Angle") 
```

The above results from our K Nearest Neighbors approximation of location show, without accounting for the angle of the signal and limiting the possible location based on angle that the signal was received at, we get the best KNN result when using K=10 with a mean square error of 240.25. This will be the benchmark to beat with other methodologies explored below.

We want to improve these results by limiting the angle observed and using the best possible K within the KNN prediction. The following graphs assist us in achieving both of these goals.

```{r, include=FALSE}

pred_XY_Nbr_Ang <- function(offlineByAvgSig, onlineByAvgSig, k){
  results <- data.frame(posXest=numeric(), posYest=numeric(), posX=numeric(),  posY=numeric())
  
  possibleAngles <- c(0,  45,  90, 135, 180, 225, 270, 315)
  
  # Goes through all possible online angles and runs KNN only on a filtered
  # offline group containing only the neighboring angles. Each group is a set
  # of online observations sharing the same angle. This group then uses KNN
  # on the offline group with the same angle and the angles directly to the 
  # left and right. After all the possible online angles are predicted, the
  # results are scored.
  for (ang in possibleAngles){ 
    angleLeft <- (ang - 45 + 360)%%360
    angleRight <-(ang + 45 + 360)%%360
    
    offline_signals <- select( 
      filter(offlineByAvgSig, angle %in% c(angleLeft, ang, angleRight)), 
      -posXY, -posX, -posY, -angle)
    
    offline_posX <- select(
      filter(offlineByAvgSig, angle %in% c(angleLeft, ang, angleRight)), 
      posX)
    
    offline_posY <- select(
      filter(offlineByAvgSig, angle %in% c(angleLeft, ang, angleRight)), 
      posY)
    
    online_signals <- select(
      filter(onlineByAvgSig, angle == ang),
      -posXY, -posX, -posY, -angle)
    
    online_positions_val <- select(
      filter(onlineByAvgSig, angle == ang),
      posX, posY)
    
    estXY <- predictXYKNN(offline_signals, online_signals, 
                          offline_posX, offline_posY, k)
    
    # The results of each group have to be combined before scoring
    results <- rbind(results, cbind(estXY, online_positions_val))
  }
  return(results)
}

# function to evaluate a series of k values and only looking at angle directly
# to the left or the right
k_Eval <- function(offlineByAvgSig, onlineByAvgSig, k_max){
  ks=numeric()
  MSE=numeric()
  
  for (k in 1:k_max){
    ks[k] <- k
    results <- pred_XY_Nbr_Ang(offlineByAvgSig, onlineByAvgSig, k)
    #MSE of all the completed online predictions
    MSE[k] <- sum( rowSums( (results[,c("posXest","posYest")] - results[,c("posX","posY")])^2) )
  }
  return(data.frame(k=ks, MSE=MSE))
}
```

```{r, echo=FALSE}
mse_allsigs <-  k_Eval(offlineByAvgSig, onlineByAvgSig, 20)
mse_allsigs$Method <- "All Signals"

mse_6sigscc <- k_Eval(select(offlineByAvgSig, -sig_c0), select(onlineByAvgSig, -sig_c0), 20)
mse_6sigscc$Method <- "6 Signals - sig_cd"

mse_6sigsco <-  k_Eval(select(offlineByAvgSig, -sig_cd), select(onlineByAvgSig, -sig_cd), 20) 
mse_6sigsco$Method <- "6 Signals - sig_c0"

mse_all_no_wt <- rbind(mse_allsigs, mse_6sigscc, mse_6sigsco, signals_only)

ggplot(mse_all_no_wt, aes(k, MSE)) + 
  geom_line(aes(color=Method), size=.9) + 
  theme_classic() + 
  scale_colour_manual(values=c("#0C38E8","#0CE85A", "#00E6FF", "black")) +
  labs(title="(Fig. 4) - Three Signal Methods - Unweighted") 

```

```{r}
# Table - Best Results by Method
kable(mse_all_no_wt %>% 
        group_by(Method) %>% 
        top_n(-1,MSE) %>% # the -1 makes it the bottom first rather than top first. 
        arrange(MSE) %>% 
        select(Method, k, MSE), 
      caption="Best Results - Unweighted")
```

```{r}
# Create weighted data

wt_signals <- function(ByAvgSig){
  signals <- select(ByAvgSig, -posXY, -posX, -posY, -angle) 
  loc_ang <- select(ByAvgSig, posXY, posX, posY, angle)
  
  weighted_signals <- (1/signals) / rowSums(1/signals)
  
  return(cbind(loc_ang, weighted_signals))
}

wtOfflineByAvgSig <- wt_signals(offlineByAvgSig)
wtOnlineByAvgSig <- wt_signals(onlineByAvgSig)
```

From Figure 4 above, we are able to determine the best value of K to use when predicting the location of the signal reading device. We find that the optimal K when including data from all seven MAC addresses is 4, which leads to an MSE of 201.34. When the address 00:0f:a3:39:e1:c0 is removed from the list, we use a K of 8 to obtain the best MSE of 207.23. Finally, removing the address 00:0f:a3:39:dd:cd, as is done by the original research team, results in a K of 5 with an MSE of 264.20.

From these results, we determine that the best method of calculating location is to retain observations from all seven MAC addresses which produces the smallest error, and thus, better accuracy. However, if we were to know for certain there are only supposed to be 6 access points on the floor and wanted to select a MAC address for elimination, then among the two tagged as being in the same spot, 00:0f:a3:39:dd:cd and 00:0f:a3:39:e1:c0, it is best to remove 00:0f:a3:39:e1:c0 instead of 00:0f:a3:39:dd:cd to achieve a smaller error when predicting the location of the device.

### Weighted Signals

In an attempt to improve the accuracy of predicting location, we up-weight stronger signals relative to weaker signals. This allows us to give strong, closer signals a larger impact on determining the location than those that are weak and further away. We use the weighting fraction below to achieve this result, where we use the signal strength as an estimator for distance.

$$\frac{1/d}{\sum_{i=1}^k 1/d_i}$$

From the results in Figure 5 below, it seems that by weighting the signal strength, our estimate of distance, we do not improve the accuracy of the nearest neighbor calculation. Without weighting the best MSE was 201.34 while we see an MSE of 335.45 with the weighting. Removing 00:0f:a3:39:e1:c0 instead of 00:0f:a3:39:dd:cd still provides the best accuracy result. For the case of weighting, it is not advised to leave both signals in, as the use of 6 signals with 00:0f:a3:39:dd:cd included produces the best MSE of 335.45 compared to the MSE of 335.70 when all 7 MAC addresses are included. None of the weighted methods exceed the benchmark.
```{r}

mse_allsigswt <-  k_Eval(wtOfflineByAvgSig, wtOnlineByAvgSig, 20)
mse_allsigswt$Method <- "All Weighted Signals"

mse_6sigsccwt <- k_Eval(select(wtOfflineByAvgSig, -sig_c0), select(wtOnlineByAvgSig, -sig_c0), 20)
mse_6sigsccwt$Method <- "6 Weighted Signals - dd:cd"

mse_6sigscowt <-  k_Eval(select(wtOfflineByAvgSig, -sig_cd), select(wtOnlineByAvgSig, -sig_cd), 20) 
mse_6sigscowt$Method <- "6 Weighted Signals - e1:c0"

mse_all_wt <- rbind(mse_allsigswt, mse_6sigsccwt, mse_6sigscowt, signals_only)

ggplot(mse_all_wt, aes(k, MSE)) + 
  geom_line(aes(color=Method), size=.9) + 
  theme_classic() + 
  scale_colour_manual(values=c("#E8AD0C", "#E8110C", "#FF6800", "black")) +
  labs(title="(Fig. 5) - Three Signal Methods - Weighted") 

```
Table - Best Results by Weighted Methods
```{r}
# Table - Best Results by Method
kable(mse_all_wt %>% 
        group_by(Method) %>% 
        top_n(-1,MSE) %>% 
        arrange(MSE) %>% 
        select(Method, k, MSE),
      caption = "Best Results - Weighted")
```

Figure 6 summarizes the discussed methodologies. Only the two methods using 6 signals with sig_cd or all unweighted signals managed to exceed the benchmark.
```{r}
mse_all <- rbind(mse_allsigs, mse_6sigscc, mse_6sigsco, 
                 mse_allsigswt, mse_6sigsccwt, mse_6sigscowt, signals_only)

ggplot(mse_all, aes(k, MSE)) + 
  geom_line(aes(color=Method), size=.9) + 
  theme_classic() + 
  scale_colour_manual(values=c("#0C38E8","#0CE85A", "#E8AD0C", 
                               "#E8110C", "#00E6FF","#FF6800", "black")) +
  labs(title="(Fig. 6) - Three Signal Methods - Unweighted and Weighted") 

```

Table - Best Results by All Methods
```{r}
# Table - Best Results by Method
kable(mse_all %>% 
        group_by(Method) %>% 
        top_n(-1,MSE) %>% 
        arrange(MSE) %>% 
        select(Method, k, MSE),
      caption = "Best Results - All")
```



```{r}

best_all_sig <- pred_XY_Nbr_Ang(offlineByAvgSig, onlineByAvgSig, 4)
best_cc <-  pred_XY_Nbr_Ang(select(offlineByAvgSig, -sig_c0), select(onlineByAvgSig, -sig_c0), 8)
best_c0 <-  pred_XY_Nbr_Ang(select(offlineByAvgSig, -sig_cd), select(onlineByAvgSig, -sig_cd), 6) 


best_all_sig_dists <- best_all_sig %>% 
  transmute(Dist = sqrt((posX - posXest)^2 + (posY - posYest)^2)) %>% 
  arrange(desc(Dist))
best_all_sig_dists$Method <- "Best All Signals - k=4"
best_all_sig_dists$Index <- seq.int(nrow(best_all_sig_dists))

best_cc_dists <- best_cc %>% 
  transmute(Dist = sqrt((posX - posXest)^2 + (posY - posYest)^2)) %>% 
  arrange(desc(Dist))
best_cc_dists$Method <- "Best 6 Signals dd:cd - k=8"
best_cc_dists$Index <- seq.int(nrow(best_cc_dists))

best_c0_dists <- best_c0 %>% 
  transmute(Dist = sqrt((posX - posXest)^2 + (posY - posYest)^2)) %>% 
  arrange(desc(Dist))
best_c0_dists$Method <- "Best 6 Signals e1:c0 - k=6"
best_c0_dists$Index <- seq.int(nrow(best_c0_dists))

best_no_wt <- rbind(best_all_sig_dists, 
                    best_cc_dists,
                    best_c0_dists)

ggplot(best_no_wt, aes(y = Dist, x=Index, color=Method)) + 
  geom_area(stat="identity", size=.1, position = position_dodge(width = 0.0), alpha=.15, aes(fill=Method))+ 
  scale_colour_manual(values=c("#0C38E8","#0CE85A", "#00E6FF")) +
  scale_fill_manual(values=c("#0C38E8","#0CE85A", "#00E6FF")) +
  labs(title="(Fig. 7) Area Plot of Sorted Errors ") +
  theme_classic() 
```
The above figure 7 shows the sorted distant errors from the true location to the predicted location of the 3 methods without weighting using the best k as previously discussed. The higher the line the larger the error for the series of points. The plot gives evidence signal dd:cd is superior to e1:c0 as the "Best 6 Signals dd:cd" is consistently below "Best 6 Signals e1:c0."  Compared to the "Best 6 Signals dd:cd", using all signals outperforms for a certain group towards the left side of the table, between Index 3 to 18, however, "Best 6 Signals dd:cd" outperforms between Index 20 to 35, but not as much to have a better MSE.

Figure 8 plots the predicted points error from the actual locations, and figure 9 shows that approximately 75% of the predicted locations for the Best All Signals method were within 2 meters.
```{r}
ggplot(building, aes(x=posX, y=posY)) + 
  geom_point(aes(shape=Type, color=Type)) + 
  geom_text(data=filter(AP, !(Label %in% c("sig_90", "sig_8d"))), aes(label=Label), nudge_y = -.6) +
  geom_text(data=filter(AP, Label == "sig_90"), aes(label=Label), nudge_x = 2) +
  geom_text(data=filter(AP, Label == "sig_8d"), aes(label=Label), nudge_x = -2) +
  labs(title="(Fig. 8) Floor Plan - Error Bars for Best KNN Using All Signals - No Weighting") + 
  scale_shape_manual(values = c(8,16,16)) +
  scale_colour_manual(values=c("red","black","#0DC3FF")) +
  theme_bw() +
  theme(axis.title.x=element_blank(), 
        axis.title.y=element_blank(), 
        axis.text.x=element_blank(), 
        axis.text.y=element_blank(),
        panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(),
        axis.ticks=element_blank()) + 
  geom_segment(data=best_all_sig, aes(x = posX, y=posY, xend = posXest, yend = posYest), color="red", size=1)
```
```{r, fig.height=1.5, fig.width=5}
ggplot(best_all_sig_dists, aes(x=Method, y=Dist)) +
  geom_boxplot() +
  theme_classic() + 
  coord_flip() +
  labs(title="(Fig. 9) Distribution of Distance\nErrors of Best All Signals")
```

### Improvements and Future Work

The models we used to look at the signals consisted of the signals for all of the possible angles and the angle we were observing and the angles 45 degrees away on either side. It is possible that there are other angle combinations besides this one that would produce better results. We observed all the angles included which produced worse results, an MSE of 252.47 in the best case, than using just 3 of the angles available, which produced an MSE of 201.34 at its best. There is the possibility of additional angles, or other combination of angles, that would produce a better prediction of locations.

It would also be interesting to observe how location on the floor affects the overall signal from specific access points. From the histograms in Figure 3, there seems to be correlation between the number of walls between an access point and the signal strength. If we observe the frequency of signals originating from the address ending in 90, there seems to be a dip between signals -60 and -65. This could be subject to some additional walls that interfere with the signal and don't allow an accurate representation of what the signal strength should be at a given location. The inverse of this can be demonstrated by the access point whose address ends in 81, which has a normal distribution of signals which seems to suggest that its signal reaches each point without the interference of additional walls.

Taking this into consideration, the weighting function previously used to weight the signals could potentially be changed to improve the results. The current method assumes that the signal strength is directly related to distance, and therefore is used in place of distance to weight the signal. It is possible that there is a different relationship between signal strength and distance that would better relate the two and give more accurate predictions of location. Each of these changes, either separate or in conjunction with one another, could be used in future analysis to potentially improve upon our results.

### Bibliography

Nolan, Deborah, and Duncan Lang. <i>Data Science in R: A Case Studies Approach to Computational Reasoning and Problem Solving</i>. CRC Press, 2015. Chapter 1.

Nolan, Deborah, and Duncan Lang. <i>Case Studies in Data Science with R</i>. Duncan Lang, 2015. http://www.rdatasciencecases.org/.

Wickham, Hadley. <i>ggplot2</i>. RStudio. http://docs.ggplot2.org/current/index.html. 